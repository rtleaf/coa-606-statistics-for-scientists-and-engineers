<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Fundamentals_of_Statistics.utf8</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/united.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
      </style>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="syllabus.html">Course Syllabus</a>
</li>
<li>
  <a href="Fundamentals_of_Statistics.html">Fundamentals</a>
</li>
<li>
  <a href="Linear_Models.html">Linear Models</a>
</li>
<li>
  <a href="Maximum_Likelihood.html">Maximum Liklihood</a>
</li>
<li>
  <a href="Multilevel_Models.html">Multilevel Models</a>
</li>
<li>
  <a href="Comp_Intensive_Approaches.html">Resampling Methods</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">




</div>


<div id="introduction-to-statistical-analysis" class="section level1">
<h1><span class="header-section-number">1</span> Introduction to statistical analysis</h1>
<p>Kachigan (1986) defines statistical analysis as the:</p>
<ul>
<li><p>Data Collection,</p></li>
<li><p>Organization (including project and data management), and</p></li>
<li><p>Interpretation of data according to well-defined procedures</p></li>
</ul>
<p>In this course we will use Kachigan’s definition as a framework and focus on aspects of collection (experimental design), organization (using descriptive and inferential approaches), and interpretation.</p>
<p>One of the primary facets of quantitative analysis is the need to be creative in your approaches - the methods outlined in this class provide the foundation for analysis but the practitioner is encouraged to explore the methods and practices in their discipline to best address the needs for interpretation.</p>
<p>Indeed, this is one of the features of statistical analysis that I would like to highlight: We cannot be constrained to cookbook approaches to analysis. Every problem, every research approach, will require consideration of the means of collection, processing of data, and statistical analysis.</p>
<p>Prior to study we need to understand clearly and succinctly what the specific research focus is. Once this is unambiguous to the scientist, then the process of data collection can begin. At this stage, it is necessary to define the variables (observations) that will be collected.</p>
</div>
<div id="practical-aspects-of-statistical-analysis" class="section level1">
<h1><span class="header-section-number">2</span> Practical aspects of Statistical Analysis</h1>
<div id="data-organization-broman-and-woo-2018" class="section level2">
<h2><span class="header-section-number">2.1</span> Data Organization (Broman and Woo, 2018)</h2>
<ul>
<li><p>Spreadsheets continue to to be a primary way for data storage, analysis, and visualization</p></li>
<li><p>Multipurpose (positive and negative)</p></li>
<li><p>Can be error prone to make large sweeping changes - hard to retrace your steps. Though stand by for some guidance on this.</p></li>
<li><p>Organization is critical for reproducible research and archiving</p></li>
</ul>
</div>
<div id="consistency-and-conventions" class="section level2">
<h2><span class="header-section-number">2.2</span> Consistency and conventions</h2>
<ol style="list-style-type: decimal">
<li><p>Use consistent codes for categorical variables</p></li>
<li><p>Use a consistent fixed code for any missing values (e.g. ‘NA’, ‘NaN’, or an unfilled cell)</p></li>
<li><p>Use consistent variable names (generally these are column names)</p></li>
<li><p>Use a consistent data layout in multiple files (same column names). This allows data to be merged in a seamless way.</p></li>
<li><p>Use a consistent format for all dates (YMD, DMY, MS Excel will often read non-traditional date values as a character code that must be post-processed for analysis.)</p></li>
<li><p>Use consistent phrases in your notes. <em>Notes are data.</em> So, treating these as variables that have a binary, nominal, or ordinal value will allow you to treat these them quantitatively.</p></li>
<li><p>Be careful about extra spaces within cells. Again, MS Excel will read these as character codes that must be post-processed for analysis.</p></li>
<li><p>One variable is recorded in each cell (remember, in our scheme, a comment is a variables)</p></li>
<li><p>Strive for a rectangular data layout</p></li>
<li><p>Avoid font and cell colors as annotation</p></li>
<li><p>Use .csv or some other file back up. ASCII files, like .csv promote distribution to non-MS Excel users (yes, they do exist)</p></li>
</ol>
</div>
<div id="data-managment-adapted-from-malin-pinsky-at-rutgers-university" class="section level2">
<h2><span class="header-section-number">2.3</span> Data Managment (Adapted from Malin Pinsky at Rutgers University)</h2>
<ol style="list-style-type: decimal">
<li><p>Keep lab notebooks to record what you did, learned, or produced each day. Can be physical notebooks, text files, Evernote, Jupyter notebooks, etc.</p></li>
<li><p>Establish a mechanism to facilitate collaboration and sharing within the lab.</p></li>
</ol>
<ul>
<li><p>This could be a shared directory or project</p></li>
<li><p>Given the resources available here it is often most useful to work directly in the cloud (Dropbox, OneDrive)</p></li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li><p>Use descriptive (non-ambiguous) file names</p></li>
<li><p>Keep raw (unprocessed, un-formatted) data in a file and associated directory that is not overwritten. Instead, processing should be performed on this data and saved in an appropriately named file.</p></li>
</ol>
<ul>
<li>If we ‘clean’ the data, we often use a folder called something like “data-raw” and a folder called “data-clean” to differentiate data in its original form from data that has been manipulated. Have “master” or “original” and “tidy” versions of files and name them appropriately.</li>
</ul>
<ol start="5" style="list-style-type: decimal">
<li><p>Store raw data with metadata describing the contents of the file (i.e. what do the columns mean, how was the data collected, etc.)</p></li>
<li><p>If using data downloaded from another data source, we often have a folder called “data_dl” for downloaded data. Include the data source in a README file for reproducibility (this is like meta data and provides useful description).</p></li>
</ol>
</div>
</div>
<div id="types-of-variables" class="section level1">
<h1><span class="header-section-number">3</span> Types of Variables</h1>
<p>Properties and characteristics of an object that can assume two or more different values are called <em>variables</em>.</p>
<p>We need to understand the structure of variables - different types of measurements will necessitate the appropriate methods of analysis.</p>
<p>The next step after the completion of data collection is to organize the data into a meaningful form so that patterns, if any, emerging out of the data can be seen easily.</p>
<p>One of the common methods for organizing data is to construct frequency distributions either in a table or as a figure.</p>
<p>Frequency distribution is an organized representation of the number of observations in each category on the scale of measurement.</p>
<p>These allow researchers to have a glance at the entire data conveniently.</p>
<p>It shows whether the observations are high or low and also whether they are concentrated in one area or spread out across the entire scale.</p>
<p>Thus, frequency distribution presents a picture of how the individual observations are distributed in the measurement scale.</p>
<div id="categorical-variables-entities-are-divided-into-distinct-categories" class="section level2">
<h2><span class="header-section-number">3.1</span> Categorical Variables (entities are divided into distinct categories):</h2>
<p>Binary variable: There are only two categories.</p>
<ul>
<li><p>Dead or alive,</p></li>
<li><p>Present or absent,</p></li>
<li><p>positive or negative (e.g. for a disease),</p></li>
<li><p>the value of some quantity of interest is zero or positive,</p></li>
<li><p>or the value of some quantity of interest exceeds some threshold value.</p></li>
</ul>
<p>Nominal variable: There are more than two categories.</p>
<ul>
<li><p>Whether the subject is an omnivore, vegetarian, vegan, or carnivore.</p></li>
<li><p>The subject’s taxonomic group,</p></li>
</ul>
<p>Ordinal variable: Similar to a nominal variable but the categories are ordered.</p>
<ul>
<li><p>Whether people got a fail, a pass, a merit or a distinction in their exam.</p></li>
<li><p>Intensity of infection (e.g. none, mild, moderate, severe)</p></li>
</ul>
</div>
<div id="frequency-distribution-of-a-categorical-variable" class="section level2">
<h2><span class="header-section-number">3.2</span> Frequency Distribution of a Categorical Variable</h2>
<ul>
<li>A tally of how frequently occurring a value is among categories.</li>
</ul>
<p><img src="Fundamentals_of_Statistics_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
</div>
<div id="continuous-variables-entities-or-objects-get-a-score-on-the-ratio-scale" class="section level2">
<h2><span class="header-section-number">3.3</span> Continuous Variables (entities or objects get a score on the ratio scale):</h2>
<p>Interval variable: Equal intervals on the variable represent equal differences in the property being measured.</p>
<ul>
<li>e.g. the difference between 6 and 8 is equivalent to the difference between 13 and 15.</li>
</ul>
<p>Some examples of measurements that are continuous are:</p>
<ul>
<li><p>Density or frequency of organisms in a transect or at a sampling station,</p></li>
<li><p>Body Mass Index or some measure of condition of an organism.</p></li>
</ul>
</div>
<div id="frequency-distribution-of-a-continuous-variable" class="section level2">
<h2><span class="header-section-number">3.4</span> Frequency Distribution of a Continuous Variable</h2>
<ul>
<li>A question often asked: What interval to choose? Your knowledge of the domain will guide this.</li>
</ul>
<p>The width of the class can be determined by dividing the range of observations by the number of classes.</p>
<p>The following are some guidelines regarding class widths:</p>
<p>1.) It is advisable to have equal class widths. Unequal class widths should be used only when large gaps exist in data.</p>
<p>2.) The class intervals should be mutually exclusive and nonoverlapping.</p>
<p>3.) Open-ended classes at the lower and upper side (e.g., &lt;10, &gt;100) should be avoided.</p>
<center>
<p>Determination of the Amount of Phosphorous in Leaves: A Frequency Table of Continuous Data</p>
<table>
<thead>
<tr class="header">
<th>Phosphorous concentration</th>
<th>Frequency</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>8.1 to 8.2</td>
<td>2</td>
</tr>
<tr class="even">
<td>8.2 to 8.3</td>
<td>6</td>
</tr>
<tr class="odd">
<td>8.3 to 8.4</td>
<td>8</td>
</tr>
<tr class="even">
<td>8.4 to 8.5</td>
<td>11</td>
</tr>
<tr class="odd">
<td>8.5 to 8.6</td>
<td>17</td>
</tr>
<tr class="even">
<td>8.6 to 8.7</td>
<td>17</td>
</tr>
<tr class="odd">
<td>8.7 to 8.8</td>
<td>24</td>
</tr>
<tr class="even">
<td>8.8 to 8.9</td>
<td>18</td>
</tr>
<tr class="odd">
<td>8.9 to 9.0</td>
<td>13</td>
</tr>
<tr class="even">
<td>9.0 to 9.1</td>
<td>10</td>
</tr>
<tr class="odd">
<td>9.1 to 9.2</td>
<td>4</td>
</tr>
</tbody>
</table>
Total frequency = 130 = n
</center>
<p><Br></p>
<p><img src="Fundamentals_of_Statistics_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
</div>
<div id="other-descriptions-of-continuous-frequency-distributions" class="section level2">
<h2><span class="header-section-number">3.5</span> Other Descriptions of Continuous Frequency Distributions</h2>
<div id="range" class="section level3">
<h3><span class="header-section-number">3.5.1</span> Range</h3>
<ul>
<li>The smallest score subtracted from the largest</li>
</ul>
<p>Example:</p>
<ul>
<li>Number of friends of 11 Facebook users.</li>
<li>22, 40, 53, 57, 93, 98, 103, 108, 116, 121, 252</li>
<li>Range = 252 - 22 = 230</li>
<li>Very biased by outliers, why?</li>
</ul>
</div>
<div id="the-interquartile-range" class="section level3">
<h3><span class="header-section-number">3.5.2</span> The Interquartile Range</h3>
<ul>
<li>The values that split the sorted data into four equal parts.</li>
<li><em>First</em> or <em>lower quartile</em> (the range values of the first 25% of values in ordered sequence)</li>
<li><em>Second</em> quartile (the range values of the first 25 to 50% of values in ordered sequence)</li>
<li><em>Third</em> quartile (the range values of the first 50 to 75% of values in ordered sequence)</li>
<li><em>Fourth</em> quartile (the range values of the first 75 to 100% of values in ordered sequence)</li>
</ul>
<p><img src="Fundamentals_of_Statistics_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p><Br></p>
</div>
</div>
<div id="cumulative-distribution-of-a-continuous-variable" class="section level2">
<h2><span class="header-section-number">3.6</span> Cumulative Distribution of a Continuous Variable</h2>
<p><img src="Fundamentals_of_Statistics_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>Determination of the Amount of Phosphorous in Leaves: A Frequency Table of Continuous Data</p>
<table>
<colgroup>
<col width="25%" />
<col width="25%" />
<col width="25%" />
<col width="25%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th></th>
<th>Cummulative Frequency</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Phosphorous concentration</td>
<td>Frequency</td>
<td>Starting with Low Values</td>
<td>Starting with High Values</td>
</tr>
<tr class="even">
<td>8.15 to 8.25</td>
<td>2</td>
<td>2</td>
<td>130</td>
</tr>
<tr class="odd">
<td>8.25 to 8.35</td>
<td>6</td>
<td>8</td>
<td>128</td>
</tr>
<tr class="even">
<td>8.35 to 8.45</td>
<td>8</td>
<td>16</td>
<td>122</td>
</tr>
<tr class="odd">
<td>8.45 to 8.55</td>
<td>11</td>
<td>27</td>
<td>114</td>
</tr>
<tr class="even">
<td>8.55 to 8.65</td>
<td>17</td>
<td>44</td>
<td>130</td>
</tr>
<tr class="odd">
<td>8.65 to 8.75</td>
<td>17</td>
<td>61</td>
<td>86</td>
</tr>
<tr class="even">
<td>8.75 to 8.85</td>
<td>24</td>
<td>85</td>
<td>69</td>
</tr>
<tr class="odd">
<td>8.85 to 8.95</td>
<td>18</td>
<td>103</td>
<td>45</td>
</tr>
<tr class="even">
<td>8.95 to 9.05</td>
<td>13</td>
<td>116</td>
<td>27</td>
</tr>
<tr class="odd">
<td>9.05 to 9.15</td>
<td>10</td>
<td>126</td>
<td>14</td>
</tr>
<tr class="even">
<td>9.15 to 9.25</td>
<td>4</td>
<td>130</td>
<td>4</td>
</tr>
</tbody>
</table>
<p>Total frequency = 130 = n</p>
</div>
<div id="measures-of-central-tendency" class="section level2">
<h2><span class="header-section-number">3.7</span> Measures of central tendency</h2>
<div id="the-mode" class="section level3">
<h3><span class="header-section-number">3.7.1</span> The Mode</h3>
<ul>
<li>The most frequently occurring value in the population or sample.</li>
</ul>
</div>
<div id="the-median" class="section level3">
<h3><span class="header-section-number">3.7.2</span> The Median</h3>
<ul>
<li>The 50th percentile in the ordered data.</li>
</ul>
</div>
<div id="the-mean" class="section level3">
<h3><span class="header-section-number">3.7.3</span> The Mean</h3>
<ul>
<li>We will spend a lot of time on this.</li>
</ul>
</div>
</div>
<div id="skew-and-kurtosis" class="section level2">
<h2><span class="header-section-number">3.8</span> Skew and Kurtosis</h2>
<ul>
<li>A left-skewed distribution has a long left tail.</li>
</ul>
<p><img src="Fundamentals_of_Statistics_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<ul>
<li>A right-skewed distribution has a long right tail. <img src="Fundamentals_of_Statistics_files/figure-html/unnamed-chunk-7-1.png" width="672" /></li>
</ul>
<p><img src="Fundamentals_of_Statistics_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
</div>
<div id="some-additional-visual-representations-of-frequency" class="section level2">
<h2><span class="header-section-number">3.9</span> Some additional visual representations of frequency</h2>
<div id="frequency-polygon" class="section level3">
<h3><span class="header-section-number">3.9.1</span> Frequency polygon</h3>
<p>A frequency polygon is constructed by connecting all midpoints of the top of the bars in a histogram by a straight line without displaying the bars.</p>
<p>A frequency polygon aids in the easy comparison of two frequency distributions.</p>
<p>When the total frequency is large and the class intervals are narrow, the frequency polygon becomes a smooth curve known as the frequency curve.</p>
<p><img src="Fundamentals_of_Statistics_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
</div>
<div id="box-and-whisker-plot" class="section level3">
<h3><span class="header-section-number">3.9.2</span> Box and whisker plot</h3>
<p>This graph, first described by Tukey in 1977, can also be used to illustrate the distribution of data.</p>
<p>There is a vertical or horizontal rectangle (box), the ends of which correspond to the upper and lower quartiles (75th and 25th percentile, respectively).</p>
<p>Hence the middle 50% of observations are represented by the box.</p>
<p>The length of the box indicates the variability of the data. The line inside the box denotes the median (sometimes marked as a plus sign).</p>
<p>The position of the median indicates whether the data are skewed or not. If the median is closer to the upper quartile, then they are negatively skewed and if it is near the lower quartile, then positively skewed.</p>
<p><img src="Fundamentals_of_Statistics_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
</div>
</div>
</div>
<div id="the-normal-distribution" class="section level1">
<h1><span class="header-section-number">4</span> The Normal Distribution</h1>
<ul>
<li>The normal distribution is probably the most common distribution in all of probability and statistics.</li>
<li>One of the main reasons it crops up so much is due to the Central Limit Theorem (we will explore this).</li>
</ul>
<div id="the-normal-probability-density-function" class="section level2">
<h2><span class="header-section-number">4.1</span> The Normal Probability Density Function</h2>
<p>The probability density function for the normal distribution is defined as:</p>
<center>
<span class="math inline">\(y_i = \frac{1}{\sigma\sqrt2\pi}e^{-(x_i-\mu)^2/2\sigma^2}\)</span>
</center>
<p>We can think of the model in this way (mathematical approach):</p>
<center>
<span class="math inline">\(f(x) = \frac{1}{\sigma\sqrt2\pi}e^{-(x_i-\mu)^2/2\sigma^2}\)</span>
</center>
<p>Where the parameters (the symbols ) represent the mean, <span class="math inline">\(\mu\)</span> (the point on the x-axis where the center of the distribution is) and the standard deviation, <span class="math inline">\(\sigma\)</span> (how spread out the distribution is) of the population.</p>
<ul>
<li>What are some of the general characteristics of this model? <em>Can you describe its shape?</em></li>
<li>What are the parameters of the model? <em>These are the quantities we will estimate in the fitting process.</em></li>
<li>What are the variables used in the model? <em>These are the observations.</em></li>
</ul>
<p>Below, two distributions are plotted from the ‘Standard Normal Distribution’, in this formulation:</p>
<p><span class="math inline">\({\sigma=1}\)</span> and <span class="math inline">\({\mu=0}\)</span>.</p>
<p><img src="Fundamentals_of_Statistics_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>The normal distribution is an example of a continuous univariate probability distribution with infinite support. By infinite support, we mean that we can calculate values of the probability density function for all outcomes between <span class="math inline">\(-\infty\)</span> and <span class="math inline">\(+\infty\)</span>.</p>
<p>The output of a probability density function is <em>not a probability value.</em></p>
<p>To get the probability from a probability density function we need to find the area under the curve. So from our example distribution with mean = 0 and standard deviation = 1, we can find the probability that the outcome is between 0 and 1 by finding the area shown in the image below.</p>
<p><img src="Fundamentals_of_Statistics_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<center>
<span class="math inline">\(\int_0^1f(x;\mu,\sigma)dx = P(0 &lt; X &lt; 1)\)</span>
</center>
<p>We can read this as “the integral of the probability density function between 0 and 1 (on the left-hand side) is equal to the probability that the outcome of the random variable is between zero and 1 (on the right-hand side)”.</p>
<p>We can cover all possible values if we set our range from ‘minus infinity’ all the way to ‘positive infinity’. Therefore the following has to be true for the function to be a probability density function:</p>
<center>
<span class="math inline">\(\int_{-\infty}^{\infty}f(x)dx = 1\)</span>.
</center>
<p>One last thing here: The probability of the random variable being equal to a specific outcome is 0, because the integral over x values of x to x is equal to zero.</p>
</div>
<div id="different-means-identical-standard-deviation" class="section level2">
<h2><span class="header-section-number">4.2</span> Different Means, Identical Standard Deviation</h2>
<p><img src="Fundamentals_of_Statistics_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
</div>
<div id="same-mean-different-standard-deviation" class="section level2">
<h2><span class="header-section-number">4.3</span> Same Mean, Different Standard Deviation</h2>
<p><img src="Fundamentals_of_Statistics_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
</div>
<div id="z-scores" class="section level2">
<h2><span class="header-section-number">4.4</span> <em>Z</em>-scores</h2>
<div id="properties-of-z-scores---centering-and-scaling" class="section level3">
<h3><span class="header-section-number">4.4.1</span> Properties of <em>Z</em>-scores - Centering and Scaling</h3>
<ul>
<li>Standardizing a score with respect to the other scores in the group.</li>
<li>Expresses a score in terms of how many standard deviations it is away from the mean.</li>
<li>Converts a distribution to a z-score distribution.</li>
<li>Z-scores have mean = 0 and standard deviation = 1.</li>
</ul>
<center>
<span class="math inline">\(z_i = \frac{x_i-\bar{x}}{s}\)</span>
</center>
<table>
<colgroup>
<col width="4%" />
<col width="33%" />
<col width="44%" />
<col width="8%" />
<col width="8%" />
</colgroup>
<thead>
<tr class="header">
<th align="right">Obs</th>
<th align="right">Centered Obs (difference between the value and the mean)</th>
<th align="right">Scaled Centered Obs (Centered value divided by standard deviation, Z-score)</th>
<th align="right">Prob (obs &lt; Z)</th>
<th align="right">Prob (Obs &gt; Z)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0.599</td>
<td align="right">0.816</td>
<td align="right">0.813</td>
<td align="right">0.792</td>
<td align="right">0.208</td>
</tr>
<tr class="even">
<td align="right">-0.926</td>
<td align="right">-0.709</td>
<td align="right">-0.706</td>
<td align="right">0.240</td>
<td align="right">0.760</td>
</tr>
<tr class="odd">
<td align="right">-2.051</td>
<td align="right">-1.834</td>
<td align="right">-1.827</td>
<td align="right">0.034</td>
<td align="right">0.966</td>
</tr>
<tr class="even">
<td align="right">0.261</td>
<td align="right">0.478</td>
<td align="right">0.476</td>
<td align="right">0.683</td>
<td align="right">0.317</td>
</tr>
<tr class="odd">
<td align="right">-0.715</td>
<td align="right">-0.498</td>
<td align="right">-0.496</td>
<td align="right">0.310</td>
<td align="right">0.690</td>
</tr>
<tr class="even">
<td align="right">0.484</td>
<td align="right">0.700</td>
<td align="right">0.698</td>
<td align="right">0.757</td>
<td align="right">0.243</td>
</tr>
<tr class="odd">
<td align="right">0.425</td>
<td align="right">0.642</td>
<td align="right">0.640</td>
<td align="right">0.739</td>
<td align="right">0.261</td>
</tr>
<tr class="even">
<td align="right">1.352</td>
<td align="right">1.569</td>
<td align="right">1.563</td>
<td align="right">0.941</td>
<td align="right">0.059</td>
</tr>
<tr class="odd">
<td align="right">-0.896</td>
<td align="right">-0.679</td>
<td align="right">-0.676</td>
<td align="right">0.249</td>
<td align="right">0.751</td>
</tr>
<tr class="even">
<td align="right">-0.702</td>
<td align="right">-0.485</td>
<td align="right">-0.483</td>
<td align="right">0.314</td>
<td align="right">0.686</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th align="right">mean</th>
<th align="right">sd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">-0.217</td>
<td align="right">1.004</td>
</tr>
</tbody>
</table>
</div>
<div id="properties-of-z-scores---quantiles" class="section level3">
<h3><span class="header-section-number">4.4.2</span> Properties of <em>Z</em>-scores - Quantiles</h3>
<ul>
<li><p>1.96 definesthe top 2.5% of the distribution.</p></li>
<li><p>-1.96 defines the bottom 2.5% of the distribution.</p></li>
<li><p>As such, 95% of z-scores lie between -1.96 and 1.96.</p></li>
<li><p>99% of z-scores lie between -2.58 and 2.58.</p></li>
<li><p>99.9% of them lie between -3.29 and 3.29.</p></li>
<li><p>Let’s look at a <a href="http://www.z-table.com/">Z Table</a></p></li>
</ul>
</div>
<div id="areas-under-the-normal-curve-for-different-quantile-values" class="section level3">
<h3><span class="header-section-number">4.4.3</span> Areas under the Normal Curve for different quantile values</h3>
<p><img src="Fundamentals_of_Statistics_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
</div>
</div>
</div>
<div id="model-fitting" class="section level1">
<h1><span class="header-section-number">5</span> Model Fitting</h1>
<div id="quantifying-error" class="section level2">
<h2><span class="header-section-number">5.1</span> Quantifying Error</h2>
<ul>
<li><p>A deviation is the difference between the mean (<em>expected</em>) and the <em>observed</em> data (the outcome of the sample).</p></li>
<li><p>The deviation of <em>observed</em> and <em>expected</em> value is also called: the residual, error, or residual error</p></li>
<li><p>Deviations can be calculated by taking each score and subtracting the mean from it:</p></li>
</ul>
<p>When the normal fitting models:</p>
<center>
<span class="math inline">\(deviation = x_i - \bar{x}\)</span>
</center>
<center>
<span class="math inline">\(error_i = outcome_i - (model_i)\)</span>
</center>
<ul>
<li>In the figure below the expected value is zero, and the residual error for each of the five samples is plotted.</li>
</ul>
<p><br></p>
<p><img src="Fundamentals_of_Statistics_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>Should we use the Total Error as an estimate of uncertainty?</p>
<ul>
<li>We could sum <span class="math inline">\(i^{th}\)</span> error terms from 1 to n.</li>
</ul>
<table>
<thead>
<tr class="header">
<th>Score</th>
<th>Mean</th>
<th>Deviation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>2.6</td>
<td>-1.6</td>
</tr>
<tr class="even">
<td>2</td>
<td></td>
<td>-0.6</td>
</tr>
<tr class="odd">
<td>3</td>
<td></td>
<td>0.4</td>
</tr>
<tr class="even">
<td>3</td>
<td></td>
<td>0.4</td>
</tr>
<tr class="odd">
<td>4</td>
<td></td>
<td>1.4</td>
</tr>
<tr class="even">
<td></td>
<td>Sum =</td>
<td>0</td>
</tr>
</tbody>
</table>
<center>
<span class="math inline">\(\Sigma(x_i - \bar{x}) = 0\)</span>
</center>
</div>
<div id="sum-of-squared-errors" class="section level2">
<h2><span class="header-section-number">5.2</span> Sum of Squared Errors</h2>
<ul>
<li><p>We could add the deviations to find out the total error, but the deviations ‘cancel out’ (some are positive and others negative)</p></li>
<li><p>Therefore, we square each deviation.</p></li>
<li><p>If we add these squared deviations we get the sum of squared errors (SS).</p></li>
</ul>
<p><Br></p>
<table>
<thead>
<tr class="header">
<th>Score</th>
<th>Mean</th>
<th>Deviation</th>
<th>Sqaured Deviation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>2.6</td>
<td>-1.6</td>
<td>2.56</td>
</tr>
<tr class="even">
<td>2</td>
<td></td>
<td>-0.6</td>
<td>0.36</td>
</tr>
<tr class="odd">
<td>3</td>
<td></td>
<td>0.4</td>
<td>0.16</td>
</tr>
<tr class="even">
<td>3</td>
<td></td>
<td>0.4</td>
<td>0.16</td>
</tr>
<tr class="odd">
<td>4</td>
<td></td>
<td>1.4</td>
<td>1.96</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td>Total</td>
<td>5.20</td>
</tr>
</tbody>
</table>
<center>
<span class="math inline">\(SS = \Sigma(X - \bar{X})^2 = 5.20\)</span>
</center>
<ul>
<li>The sum of squares is a good measure of overall variability, but is dependent on the number of scores.</li>
</ul>
</div>
<div id="variance" class="section level2">
<h2><span class="header-section-number">5.3</span> Variance</h2>
<ul>
<li><p>We calculate the average variability (average variability of each sample) by dividing by the number of scores minus one (n-1).</p></li>
<li><p>The quantity n - 1 is termed <em>degrees of freedom</em>. It is the maximum number of logically independent values, those with the freedom to vary in the sample</p></li>
<li><p>The sum of squares divided by the degrees of freedom is called the variance (s<sup>2</sup>).</p></li>
</ul>
<center>
Sample variance: <span class="math inline">\(s^2 = \frac{SS}{n-1} = \frac{\Sigma(x_i-\bar{x})^2}{n-1}\)</span>
</center>
<p>Contrast this with the population variance:</p>
<center>
Population variance: <span class="math inline">\(\sigma^2 = \frac{SS}{N} = \frac{\Sigma^n_{i=1}(x_i-\mu)^2}{N}\)</span>
</center>
</div>
<div id="standard-deviation" class="section level2">
<h2><span class="header-section-number">5.4</span> Standard Deviation</h2>
<ul>
<li><p>The variance has one problem: it is measured in units<sup>2</sup> (The original units, like the numbers are squared.).</p></li>
<li><p>This isn’t a very meaningful metric so we take the square root value.</p></li>
<li><p>This is the sample standard deviation:</p></li>
</ul>
<p><span class="math inline">\(s = \sqrt\frac{\Sigma^n_{i=1}(x_i-\bar{x})^2}{n-1}\)</span></p>
<p><Br></p>
</div>
<div id="summary-of-variance-estimates" class="section level2">
<h2><span class="header-section-number">5.5</span> Summary of Variance Estimates</h2>
<p>The sum of squares, variance, and standard deviation represent the same thing:</p>
<ul>
<li>The fit of the mean to the data, how well the mean represents the observed data</li>
<li>The variability in the data when modeled using the mean</li>
</ul>
</div>
</div>
<div id="sampling-and-parameter-estimation" class="section level1">
<h1><span class="header-section-number">6</span> Sampling and Parameter Estimation</h1>
<div id="random-samples" class="section level2">
<h2><span class="header-section-number">6.1</span> Random samples</h2>
<ul>
<li><p>Every possible member of the population has an equal probability of being included in the sample.</p></li>
<li><p>Ex: scientific exit polling vs. twitter polls to estimate proportion voting for a candidate.</p></li>
<li><p>Think of a normally distributed frequency distribution as the population distribution:</p></li>
</ul>
<p>How would the sampling distribution vary if samples were non-random?</p>
<ul>
<li><p>Only statistically valid data that can be used for analysis - the first assumption of parametric statistics.</p></li>
<li><p>We will generally make an inspection of the data and/or the residuals to ensure that they are normally distributed.</p></li>
<li><p>Ensuring that data are collected in a random fashion allows statistics to be calculated. Non-random data collection disallows this.</p></li>
<li><p>Independence is also a critical aspect of sampling - the sampling of one element will not impact or predict the value of another element.</p></li>
</ul>
</div>
<div id="parameter-estimates---unbiased" class="section level2">
<h2><span class="header-section-number">6.2</span> Parameter Estimates - Unbiased</h2>
<ul>
<li><p>Parameters are estimated quantities that could describe any number of population characteristics (the characteristics of variables).</p></li>
<li><p>We are generally focused on the mean and variance, estimated parameters could be the mean, median, mode.</p></li>
<li><p>One aspect of parameter estimation is to get a <em>point estimate</em> - approximation of the true value of the population, but does not provide information about the precision of the estimate.</p></li>
<li><p>The best estimate of <span class="math inline">\(\mu\)</span> is <span class="math inline">\(\bar{x}\)</span>.</p></li>
<li><p>The best estimate of <span class="math inline">\(\sigma\)</span> is <span class="math inline">\(s\)</span>.</p></li>
<li><p>We strive for an unbiased estimate of population paramters: Unbiased means that the expected value is equal to the true value (accuracy)</p></li>
</ul>
</div>
<div id="parameter-estimates---efficient" class="section level2">
<h2><span class="header-section-number">6.3</span> Parameter Estimates - Efficient</h2>
<ul>
<li><p>The second property we want is to have parameters be efficient</p></li>
<li><p>This has to do with the relationship of variance to sample size and is concerned with understanding how does sampling impact the estimate - variance should be reduced when sampling is increased.</p></li>
</ul>
</div>
<div id="interval-estimation" class="section level2">
<h2><span class="header-section-number">6.4</span> Interval Estimation</h2>
<ul>
<li><p>Reporting point estimates alone is unsatisfactory - we need an estimate of the variation.</p></li>
<li><p>We want to know how close the sample statistic is to the population parameter.</p></li>
<li><p>Interval estimation is concerned making statements saying how confident or certain we are that the populaiton parameter resides in an interval of values.</p></li>
<li><p>e.g. There is a 0.95 probability that the value of <span class="math inline">\(\mu\)</span> resides between 6.2 and 9.7.</p></li>
</ul>
</div>
<div id="confidence-interval" class="section level2">
<h2><span class="header-section-number">6.5</span> Confidence Interval</h2>
<ul>
<li>Confidence intervals involve:</li>
</ul>
<ol style="list-style-type: decimal">
<li><p>Identification of associated probability</p></li>
<li><p>Specification of the interval</p></li>
</ol>
<ul>
<li><p>So how do we determine confidence intervals in practice:</p></li>
<li><p>In the first case, let’s use or general equation for a statistical model:</p></li>
</ul>
<p><span class="math inline">\(Statistic = Parameter \pm Error\)</span> (From Kachigan, p. 138)</p>
<p><span class="math inline">\(Paramter = Statistic \pm Error\)</span></p>
<p><span class="math inline">\(\mu = \bar{x} \pm Error\)</span></p>
<ul>
<li>We will never know the magnitude of the true error? How large is the combined effect of sampling and process error. However, we can attach a probability that the error is a certain size. Now, we want to solve for the Statistic.</li>
</ul>
<p><span class="math inline">\(\bar{x} = \mu \pm Error\)</span></p>
<ul>
<li><p>If we take an infinite number of samples from the population, we will get an estimate of the error term, <span class="math inline">\(\sigma\)</span>.</p></li>
<li><p>The error in sampling, from an <em>infinite</em> number of samples, is equal to the variation in the sample means, the standard distribution (sd) equals the standard error of the mean.</p></li>
<li><p>So this takes us back to our <em>Z</em>-score:</p></li>
<li><p>What is the z value in which 95% of the values are under the curve?</p></li>
<li><p>Let’s look at a <a href="http://www.z-table.com/">Z Table</a></p></li>
</ul>
<p><img src="Fundamentals_of_Statistics_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<p><span class="math inline">\(\mu = \bar{x} \pm 1.96\sigma\)</span> (95% Certainty)</p>
<p><span class="math inline">\(\mu = \bar{x} \pm ? \sigma\)</span> (99% Certainty)</p>
<ul>
<li>The above presumes that we have a very good knowledge of the population parameter <span class="math inline">\(\sigma\)</span>, which is generally not the case. We do not sample populations and infinite number of times.</li>
</ul>
</div>
<div id="confidence-intervals-of-the-mean-from-samples---using-the-t-distribution" class="section level2">
<h2><span class="header-section-number">6.6</span> Confidence Intervals of the Mean from samples - using the t-distribution</h2>
<ul>
<li><p>The determination of the sampling interval from populations with unknown <span class="math inline">\(\sigma\)</span> we will use our best estimate of <span class="math inline">\(\sigma\)</span>, which is <em>s</em>.</p></li>
<li><p>Similarly, we will use the <em>t</em> distribution to model the variability, you will see that it is flatter and has larger tails - what does this mean to our estimate of the confidence interval?</p></li>
<li><p>The <em>t</em> distribution is a one parameter distribution, <em>df</em> is the parameter and it controls the shape of the distribution. The model is platykurtic at small sample sizes.</p></li>
<li><p><em>df</em> is <em>n</em> - 1.</p></li>
<li><p>To model the confidence interval we assume that the distribution of the variables are normally distributed.</p></li>
<li><p>Allow us to determine the interval estimates of an estimated parameter, contingent on the values of estimates of parameters derived from sampling, in a probabilistic way.</p></li>
<li><p>Let’s look at a <a href="http://www.ttable.org/">t Table</a></p></li>
</ul>
<p><span class="math inline">\(\mu = \bar{x} \pm t_{df}{s_{\bar{x}}}\)</span> (95% Certainty, with <em>n</em> = 10?)</p>
<p><span class="math inline">\(\mu = \bar{x} \pm t_{df}{s_{\bar{x}}}\)</span> (99% Certainty, with <em>n</em> = 10?)</p>
<p><span class="math inline">\(\mu = \bar{x} \pm t_{df}{s_{\bar{x}}}\)</span> (99% Certainty, with <em>n</em> = 50?)</p>
</div>
</div>
<div id="hypothesis-testing-and-power" class="section level1">
<h1><span class="header-section-number">7</span> Hypothesis Testing and Power</h1>
<div id="statistical-hypothesis-testing" class="section level2">
<h2><span class="header-section-number">7.1</span> Statistical Hypothesis Testing</h2>
<ul>
<li><p>State a testable hypothesis</p></li>
<li><p><span class="math inline">\(H_0\)</span> Null hypothesis</p></li>
<li><p><span class="math inline">\(H_A\)</span> Alternative hypothesis</p></li>
<li><p>Declare <span class="math inline">\(\alpha\)</span> level</p></li>
<li><p>Collect Data</p></li>
<li><p>Compare the test statistic to the critical value (determined by alpha)</p></li>
<li><p>State the resulting probability</p></li>
<li><p>State testable hypothesis</p></li>
<li><p>These are a set of mutually exclusive and exhaustive outcomes</p></li>
<li><p>The test statistic will support one or the other outcomes</p></li>
</ul>
<p><Br></p>
<p><span class="math inline">\(H_0: \mu = 0\)</span>, <span class="math inline">\(H_A:\mu \ne 0\)</span></p>
<p><span class="math inline">\(H_0: \mu = 3.5 cm\)</span>, <span class="math inline">\(H_A:\mu \ne 3.5 cm\)</span></p>
<p><span class="math inline">\(H_0: \mu = 10.5 kg\)</span>, <span class="math inline">\(H_A:\mu \ne 10.5 kg\)</span></p>
<p><Br></p>
</div>
<div id="example-use-z-score-to-evaluate-if-it-is-likely-that-a-given-value-of-the-distribution-is-the-mean-value" class="section level2">
<h2><span class="header-section-number">7.2</span> Example: Use <em>Z</em>-score to evaluate if it is likely that a given value of the distribution is the mean value</h2>
<ul>
<li><p>Is the mean fuel consumption of a population of buses equal to 20 mpg?</p></li>
<li><p>What is the null hypothesis?</p></li>
<li><p>We need information about the population (remember we are using <em>Z</em>-score so we know the population-level parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>).</p></li>
<li><p>Mean</p></li>
<li><p>Population standard deviation</p></li>
<li><p>Calculate <em>Z</em>-score for mean = 20 mpg</p></li>
<li><p>Determine the associated probability that the mean is 20 mpg given:</p></li>
<li><p><span class="math inline">\(\sigma\)</span> = 0.3, <span class="math inline">\(\mu\)</span> = 19.1</p></li>
</ul>
</div>
<div id="evaluate-z-score" class="section level2">
<h2><span class="header-section-number">7.3</span> Evaluate <em>Z</em>-score</h2>
<p>What is the probability that we would get this <em>Z</em>-score?</p>
<p>Hypothetical <em>Z</em>-scores</p>
<p><Br></p>
<p><img src="Fundamentals_of_Statistics_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p><Br> <Br></p>
<table>
<thead>
<tr class="header">
<th>z</th>
<th>.00</th>
<th>.01</th>
<th>.02</th>
<th>.03</th>
<th>.04</th>
<th>.05</th>
<th>.06</th>
<th>.07</th>
<th>.08</th>
<th>.09</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0.0</td>
<td>.5000</td>
<td>.5040</td>
<td>.5080</td>
<td>.5120</td>
<td>.5160</td>
<td>.5199</td>
<td>.5239</td>
<td>.5279</td>
<td>.5319</td>
<td>.5359</td>
</tr>
<tr class="even">
<td>0.1</td>
<td>.5398</td>
<td>.5438</td>
<td>.5478</td>
<td>.5517</td>
<td>.5557</td>
<td>.5596</td>
<td>.5636</td>
<td>.5675</td>
<td>.5714</td>
<td>.5753</td>
</tr>
<tr class="odd">
<td>0.2</td>
<td>.5793</td>
<td>.5832</td>
<td>.5871</td>
<td>.5910</td>
<td>.5948</td>
<td>.5987</td>
<td>.6026</td>
<td>.6064</td>
<td>.6103</td>
<td>.6141</td>
</tr>
<tr class="even">
<td>0.3</td>
<td>.6179</td>
<td>.6217</td>
<td>.6255</td>
<td>.6293</td>
<td>.6331</td>
<td>.6368</td>
<td>.6406</td>
<td>.6443</td>
<td>.6480</td>
<td>.6517</td>
</tr>
<tr class="odd">
<td>0.4</td>
<td>.6554</td>
<td>.6591</td>
<td>.6628</td>
<td>.6664</td>
<td>.6700</td>
<td>.6736</td>
<td>.6772</td>
<td>.6808</td>
<td>.6844</td>
<td>.6879</td>
</tr>
<tr class="even">
<td>0.5</td>
<td>.6915</td>
<td>.6950</td>
<td>.6985</td>
<td>.7019</td>
<td>.7054</td>
<td>.7088</td>
<td>.7123</td>
<td>.7157</td>
<td>.7190</td>
<td>.7224</td>
</tr>
<tr class="odd">
<td>0.6</td>
<td>.7257</td>
<td>.7291</td>
<td>.7324</td>
<td>.7357</td>
<td>.7389</td>
<td>.7422</td>
<td>.7454</td>
<td>.7486</td>
<td>.7517</td>
<td>.7549</td>
</tr>
<tr class="even">
<td>0.7</td>
<td>.7580</td>
<td>.7611</td>
<td>.7642</td>
<td>.7673</td>
<td>.7704</td>
<td>.7734</td>
<td>.7764</td>
<td>.7794</td>
<td>.7823</td>
<td>.7852</td>
</tr>
<tr class="odd">
<td>0.8</td>
<td>.7881</td>
<td>.7910</td>
<td>.7939</td>
<td>.7967</td>
<td>.7995</td>
<td>.8023</td>
<td>.8051</td>
<td>.8078</td>
<td>.8106</td>
<td>.8133</td>
</tr>
</tbody>
</table>
<p><Br></p>
</div>
<div id="is-it-meaningful" class="section level2">
<h2><span class="header-section-number">7.4</span> Is it meaningful?</h2>
<p>Declare <span class="math inline">\(\alpha\)</span></p>
<ul>
<li>Given our <span class="math inline">\(\alpha\)</span> level, how does the resulting probability compare?</li>
<li>Remember, <span class="math inline">\(\alpha\)</span> is defined prior to statistical testing</li>
<li>Two tail and one tail test</li>
</ul>
<p><img src="Fundamentals_of_Statistics_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<p><Br></p>
</div>
<div id="statistical-hypothesis-testing-1" class="section level2">
<h2><span class="header-section-number">7.5</span> Statistical Hypothesis Testing</h2>
<p>Evaluate if the population mean is not significantly different from some specified value.</p>
<p><span class="math inline">\(H_0\)</span>: <span class="math inline">\(\mu\)</span> = 0</p>
<p><span class="math inline">\(H_A: \mu \ne 0\)</span></p>
<p>Introduce the idea of a critical value (critical quantile)</p>
<ul>
<li><span class="math inline">\(\alpha\)</span> of 0.05</li>
</ul>
<p>We have data taken from the weight change in horses given some medical treatment.</p>
<p>We are interested to know if the mean change in weight that we found +1.29 kg is significantly different from 0 kg.</p>
<ul>
<li>We calculate the <em>Z</em>-score and find that <em>Z</em> = 1.45</li>
</ul>
<p><span class="math inline">\(P(mean \ge 1.29) = P(Z \ge 1.45) = ?\)</span></p>
<p><span class="math inline">\(P(mean \le 1.29) = P(Z \le 1.45) = ?\)</span></p>
<p>Z = 1.96 is the rejection region at 2.5%</p>
<ul>
<li>This is the ‘region of rejection’</li>
</ul>
<p>Now we have a way to objectively reject or accept the null hypothesis.</p>
<p><img src="Fundamentals_of_Statistics_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p><Br></p>
<div id="one--and-two-tailed-tests" class="section level3">
<h3><span class="header-section-number">7.5.1</span> One- and Two-Tailed Tests</h3>
<p>Alternative to testing ‘is the value different.’</p>
<p>In some cases we care about the direction of the difference (is the value less than or greater than some value).</p>
<p>Use one-tailed test</p>
<ul>
<li>In general, one-tailed hypotheses about a mean are:</li>
<li><span class="math inline">\(H_0:\mu\ge\mu_0\)</span> and <span class="math inline">\(H_A:\mu&lt;\mu_0\)</span></li>
<li>In which case, H<sub>0</sub> is rejected if the test statistic is in the left-hand tail of the distribution or:</li>
<li><span class="math inline">\(H_0:\mu\le\mu_0\)</span> and <span class="math inline">\(H_A:\mu&gt;\mu_0\)</span></li>
</ul>
<p>Contrast the region of rejection for these.</p>
<p><img src="Fundamentals_of_Statistics_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p><Br></p>
</div>
</div>
<div id="type-1-and-type-2-errors" class="section level2">
<h2><span class="header-section-number">7.6</span> Type-1 and Type-2 Errors</h2>
<p>Sometimes we:</p>
<ul>
<li>Reject the null hypothesis when it is true.</li>
<li>Accept the alternative hypothesis when it is false.</li>
</ul>
<p>Type 1 error or alpha error - frequency of rejecting <span class="math inline">\(H_0\)</span> when it is true.</p>
<p>Type 1 error rate is equal to <span class="math inline">\(\alpha\)</span>.</p>
<p>Type 1 error: “rejecting the null hypothesis when it is true.” We rejected the null hypothesis but did so erroneously.</p>
<p>Type 1 error is termed ‘<span class="math inline">\(\alpha\)</span> error’ because it is equal to <span class="math inline">\(\alpha\)</span></p>
<p>Now we have some criteria to choose alpha.</p>
<p>So if your <span class="math inline">\(\alpha\)</span>, or critical value is 0.10 we have a 10% probability of rejecting the null hypothesis when we should have, in fact, accepted it.</p>
<div id="type-1-alpha-error" class="section level3">
<h3><span class="header-section-number">7.6.1</span> Type 1 (<span class="math inline">\(\alpha\)</span>) Error</h3>
<p><img src="Fundamentals_of_Statistics_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<p><em>Figure 4.8.1</em></p>
<p><Br></p>
<p>Type 2 error: “accepting the null hypothesis when it is false.”</p>
<p>Type 2 error or ‘<span class="math inline">\(\beta\)</span> error’ is equal to <span class="math inline">\(\beta\)</span>.</p>
<p><Br></p>
<table>
<thead>
<tr class="header">
<th></th>
<th>If H<sub>0</sub> is true</th>
<th>If H<sub>0</sub> is false</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>If H<sub>0</sub> is rejected</td>
<td>Type I error</td>
<td>No error</td>
</tr>
<tr class="even">
<td>If H<sub>0</sub> is not rejected</td>
<td>No error</td>
<td>Type II error</td>
</tr>
</tbody>
</table>
<p><em>Table 4.8.1:  Two Types of Errors in Hypothesis Testing</em></p>
<p><Br></p>
<p>Thought experiments:</p>
<ul>
<li>Ex. Endangered species conservation</li>
<li>Ex. Pharmaceutical testing</li>
</ul>
<p><Br></p>
<table>
<thead>
<tr class="header">
<th></th>
<th>If H<sub>0</sub> is true</th>
<th>If H<sub>0</sub> is false</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>If H<sub>0</sub> is rejected</td>
<td><span class="math inline">\(\alpha\)</span></td>
<td><span class="math inline">\(1-\beta\)</span> (“power”) No error</td>
</tr>
<tr class="even">
<td>If H<sub>0</sub> is not rejected</td>
<td>No error <span class="math inline">\(1-\alpha\)</span></td>
<td><span class="math inline">\(\beta\)</span></td>
</tr>
</tbody>
</table>
<p><em>Table 4.8.2:  Long-term Probabilities of Outcomes in Hypothesis Testing</em></p>
<p><Br></p>
</div>
<div id="power" class="section level3">
<h3><span class="header-section-number">7.6.2</span> Power</h3>
<p>Power: the probability that a statistical test will reject a null hypothesis when it is false (proper rejection).</p>
<p><Br></p>
<p><img src="Fundamentals_of_Statistics_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<p><em>Figure 4.9.1</em></p>
<p><Br> <Br></p>
<p><img src="Fundamentals_of_Statistics_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<p><em>Figure 4.9.2</em></p>
<p><Br></p>
</div>
<div id="leafs-power-simulation-in-r" class="section level3">
<h3><span class="header-section-number">7.6.3</span> Leaf’s power simulation in R</h3>
<p><Br></p>
</div>
<div id="what-influences-statistical-power" class="section level3">
<h3><span class="header-section-number">7.6.4</span> What Influences Statistical Power?</h3>
</div>
</div>
</div>
<div id="parameteric-and-non-parameteric-correlation" class="section level1">
<h1><span class="header-section-number">8</span> Parameteric and Non-Parameteric Correlation</h1>
<div id="correlation" class="section level2">
<h2><span class="header-section-number">8.1</span> Correlation</h2>
<p>Correlations is a way of measuring the extent to which two variables are related.</p>
<p>Parametric approaches</p>
<ul>
<li>Pearson’s correlation coefficient</li>
</ul>
<p>Nonparametric approaches</p>
<ul>
<li>Spearman’s rho</li>
<li>Kendall’s tau</li>
</ul>
<p>Interpreting correlations</p>
<p>Small Relationship</p>
<p><img src="Fundamentals_of_Statistics_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<p>Positive Relationship</p>
<p><img src="Fundamentals_of_Statistics_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<p>Negative Relationship</p>
<p><img src="Fundamentals_of_Statistics_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
</div>
<div id="quantifying-the-magnitude-of-correlation" class="section level2">
<h2><span class="header-section-number">8.2</span> Quantifying the magnitude of correlation</h2>
<ul>
<li><p>As one variable increases, does the other increase, decrease or stay the same?</p></li>
<li><p>This can be done by calculating the covariance.</p></li>
<li><p>We look at how much each score deviates from the mean.</p></li>
<li><p>If both variables deviate from the mean by the same amount, they are likely to be related.</p></li>
</ul>
<p>Here is the results (bivariate) of an experiment aimed at understanding the efficacy of advertising:</p>
<table>
<thead>
<tr class="header">
<th>Participant</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>Mean</th>
<th>SD</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Adverts Watched</td>
<td>5</td>
<td>4</td>
<td>4</td>
<td>6</td>
<td>8</td>
<td>5.4</td>
<td>1.67</td>
</tr>
<tr class="even">
<td>Packets Bought</td>
<td>8</td>
<td>9</td>
<td>10</td>
<td>13</td>
<td>15</td>
<td>11</td>
<td>2.92</td>
</tr>
</tbody>
</table>
<p>Residual error values:</p>
<table>
<thead>
<tr class="header">
<th>Participant</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>Mean</th>
<th>SD</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Adverts Watched</td>
<td>5</td>
<td>4</td>
<td>4</td>
<td>6</td>
<td>8</td>
<td>5.4</td>
<td>1.67</td>
</tr>
<tr class="even">
<td>Packets Bought</td>
<td>8</td>
<td>9</td>
<td>10</td>
<td>13</td>
<td>15</td>
<td>11</td>
<td>2.92</td>
</tr>
<tr class="odd">
<td>Advertiser Residual</td>
<td>-0.4</td>
<td>-1.4</td>
<td>-1.4</td>
<td>0.6</td>
<td>2.6</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Packets residual</td>
<td>-3</td>
<td>-2</td>
<td>-1</td>
<td>2</td>
<td>4</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><Br></p>
<p><img src="Fundamentals_of_Statistics_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<p><img src="Fundamentals_of_Statistics_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
</div>
<div id="covariance-and-a-re-examination-of-variance" class="section level2">
<h2><span class="header-section-number">8.3</span> Covariance and a re-examination of variance</h2>
<ul>
<li><p>Remember the variance tells us by how much scores deviate from the mean for a single variable.</p></li>
<li><p>It is closely linked to the sum of squares.</p></li>
<li><p>Covariance is similar - it tells is by how much scores on two variables differ from their respective means.</p></li>
</ul>
<p><span class="math inline">\(variance=\frac{\Sigma(x_i - \bar{X})}{N-1}^2\)</span></p>
<p><span class="math inline">\(variance=\frac{\Sigma(x_i - \bar{X})(x_i - \bar{X})}{N-1}\)</span></p>
<ul>
<li><p>Calculate the error between the mean and each subject’s score for the first variable (<em>X</em>).</p></li>
<li><p>Calculate the error between the mean and their score for the second variable (<em>Y</em>).</p></li>
<li><p>Multiply these error values.</p></li>
<li><p>Add these values and you get the cross product deviations.</p></li>
<li><p>The covariance is the average cross-product deviations:</p></li>
</ul>
<p><span class="math inline">\(cov(x,y)=\frac{\Sigma(x_i - \bar{x})(y_i - \bar{y})}{N-1}\)</span></p>
<p><span class="math inline">\(cov(x,y)=\frac{(-0.4)(-3)+(-1.4)(-2)+(-1.4)(-1)+(0.6)(2)+(2.6)(4)}{4}\)</span></p>
<p><span class="math inline">\(cov(x,y)=\frac{1.2+2.8+1.4+1.2+10.4}{4}\)</span></p>
<p><span class="math inline">\(cov(x,y)=\frac{17}{4}\)</span></p>
<p><span class="math inline">\(cov(x,y)=4.25\)</span></p>
</div>
<div id="limitations-of-covariance" class="section level2">
<h2><span class="header-section-number">8.4</span> Limitations of Covariance</h2>
<p>The magnitude of the covariance is dependent on the units of measurement.</p>
<ul>
<li><p>e.g. the covariance of two variables measured in miles might be 4.25, but if the same scores are converted to kilometres, the covariance is 11.</p></li>
<li><p>Standardize: Divide by the standard deviations of both variables.</p></li>
<li><p>The standardized version of covariance is known as the correlation coefficient.</p></li>
<li><p>It is unaffected by units of measurement.</p></li>
</ul>
</div>
<div id="the-correlation-coefficient" class="section level2">
<h2><span class="header-section-number">8.5</span> The Correlation Coefficient</h2>
<p><span class="math inline">\(r=\frac{cov_xy}{s_xs_y}\)</span></p>
<p><span class="math inline">\(r=\frac{\Sigma(x_i - \bar{x})(y_i - \bar{y})}{(N-1)s_xs_y}\)</span></p>
<p><span class="math inline">\(r=\frac{cov_xy}{s_xs_y}\)</span></p>
<p><span class="math inline">\(r=\frac{4.25}{1.67 * 2.92}\)</span></p>
<p><span class="math inline">\(r=0.87\)</span></p>
<p>Termed Pearson-product moment correlation coefficient</p>
<p>It varies between -1 and +1</p>
<ul>
<li>0 = no relationship</li>
</ul>
<p>It is a testable hypothesis</p>
<p>Testing <span class="math inline">\(H_0: \rho=0\)</span> versus <span class="math inline">\(H_A: \rho\ne0\)</span></p>
<p>The standard error of the correlation coefficient is calculated as:</p>
<p><span class="math inline">\(S_r=\sqrt\frac{1-r^2}{n-2}\)</span></p>
<p>It is a testable hypothesis</p>
<p><em>r</em> = 0.870</p>
<p><em>n</em> = 12 (new data set, with more samples)</p>
<p>We will calculate the critical value:</p>
<p><span class="math inline">\(t=\frac{r}{S_r}= \frac{0.870}{0.156}= 5.58\)</span></p>
<p>t<sub>0.05(2),10</sub> =2.228</p>
<p>Testing <span class="math inline">\(H_0: \rho=0\)</span> versus <span class="math inline">\(H_A: \rho\ne0\)</span></p>
<p>Coefficient of determination, r^2</p>
<ul>
<li>By squaring the value of r you get the proportion of variance in one variable shared by the other.</li>
</ul>
</div>
<div id="non-parametric-correlation" class="section level2">
<h2><span class="header-section-number">8.6</span> Non-parametric Correlation</h2>
<p>Spearman’s rho <span class="math inline">\(\rho\)</span></p>
<ul>
<li>Pearson’s correlation on the ranked data</li>
</ul>
<p>Kendall’s tau (<span class="math inline">\(\tau\)</span>)</p>
<ul>
<li>“Better” than Spearman’s for small samples</li>
</ul>
</div>
<div id="spearman-rank-correlation-coefficient" class="section level2">
<h2><span class="header-section-number">8.7</span> Spearman Rank Correlation Coefficient</h2>
<p><em>d</em> is the difference between two numbers in each pair of ranks</p>
<p><em>n</em> = number of pairs of data</p>
<p><span class="math inline">\(r=1-(\frac{6\Sigma d^2}{n(n^2 - 1)})\)</span></p>
<table>
<thead>
<tr class="header">
<th>Data 1</th>
<th>Data 2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>6</td>
<td>2</td>
</tr>
<tr class="even">
<td>4</td>
<td>9</td>
</tr>
<tr class="odd">
<td>7</td>
<td>3</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th>Data 1</th>
<th>Data 2</th>
<th>Rank 1</th>
<th>Rank 2</th>
<th>d</th>
<th>d<sup>2</sup></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>6</td>
<td>2</td>
<td>2</td>
<td>1</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>4</td>
<td>9</td>
<td>1</td>
<td>3</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>7</td>
<td>3</td>
<td>3</td>
<td>2</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th>Data 1</th>
<th>Data 2</th>
<th>Rank 1</th>
<th>Rank 2</th>
<th>d</th>
<th>d<sup>2</sup></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>6</td>
<td>2</td>
<td>2</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="even">
<td>4</td>
<td>9</td>
<td>1</td>
<td>3</td>
<td>2</td>
<td>4</td>
</tr>
<tr class="odd">
<td>7</td>
<td>3</td>
<td>3</td>
<td>2</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>
<p><span class="math inline">\(r=1-(\frac{6\Sigma d^2}{n(n^2 - 1)})\)</span></p>
<p><span class="math inline">\(=1-(\frac{6*6}{3(3^2 - 1)})\)</span></p>
<p>We can use this value as the calculated <em>r</em> value</p>
<p>The critical value is a two tailed value with <em>n</em></p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
